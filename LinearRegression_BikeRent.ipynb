{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression for an actual data set\n",
    "\n",
    "We consider linear regression for an actual data set. We will use simple features of pandas (see https://pandas.pydata.org/) for data analysis.\n",
    "\n",
    "**There are 9 questions to answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "\n",
    "# set up the random number generator: given seed for reproducibility, None otherwise\n",
    "# (see https://numpy.org/doc/stable/reference/random/generator.html#numpy.random.default_rng)\n",
    "my_seed = 1\n",
    "rng = np.random.default_rng(seed=my_seed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset \n",
    "\n",
    "We use the \"day.csv\" dataset from https://archive-beta.ics.uci.edu/dataset/275/bike+sharing+dataset (which we renamed when downloading). This dataset records daily counts of bike rentals, together with calendar information and weather conditions. In particular, the field *cnt* gives the total number of rentals that day. This is the quantity we want to predict by linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('BikeSharingDataset.csv')\n",
    "df.head()\n",
    "df.info() # if only data types are wanted: print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning-up and constructing the data set\n",
    "\n",
    "We remove the first two columns (index of element in the dataset and exact date), as well as the distinction between casual and registered users as the corresponding features are not of interest to us. See https://www.kaggle.com/code/gauravduttakiit/bike-sharing-multiple-linear-regression for further checks and manipulations to ensure that the data is correct (checking for missing data, duplicates, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the drop() function in panda, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\n",
    "# argument 'inplace=True' to permanently remove the column\n",
    "df.drop(['instant','dteday','casual','registered'],axis=1,inplace=True)\n",
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each rental day, the following features are provided:\n",
    " - season: 1 = spring, 2 = summer, 3 = fall, 4 = winter\n",
    " - yr: year, here 0 for 2011 and 1 for 2012\n",
    " - mnth: month, numbered from 1 to 12\n",
    " - holiday: 0 if no holiday, 1 if there is a holiday (extracted from http://dchr.dc.gov/page/holiday-schedule)\n",
    " - weekday: 0 (Sunday) to 6 (Saturday)\n",
    " - workingday: 0 for non-working day, 1 for working day \n",
    " - weathersit: weather favorability rating from 1 (clear day) to 4 (rain, fog)\n",
    " - temp: normalized temperature \n",
    " - atemp: normalized temperature feels like\n",
    " - hum: normalized humidity \n",
    " - windspeed: normalized wind speed\n",
    " - cnt: the number of rented bicycles (target attribute to be predicted)\n",
    "\n",
    "So, we have features which are real numbers (*temp, atemp, hum,\twindspeed*), binary (*holiday, workingday*), and ordinal features (eg. *season, weekday, weathersit*). We can consider all of them as real numbers features. To get some idea of the data values, we can use the panda function *describe()*, which produces some descriptive statistics (see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the *yr* data is more or less evenly distributed (as the mean is close to 0.5). On the other hand, there are only a handful of holidays (see the small mean value of *holiday*), so this variable should probably not be considered.\n",
    "\n",
    "We next randomly split the data into train and test sets, before conducting any analysis, as such an analysis will be based on the train set only. This is done using a dedicated scikit-learn function (see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_train = 0.7 \n",
    "fraction_test = 1.0 - fraction_train\n",
    "df_train, df_test = train_test_split(df, train_size = fraction_train, test_size = fraction_test)\n",
    "df_train.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "\n",
    "We start by exploring the dataset to understand how the target attribute (*cnt*) depends on each of the features. We start by using the plot function of *pandas* (see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html). It would be better to do this on the training data only, but we do it on the full data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 10))\n",
    "# df_train.columns[:-1] is the list of all columns, except the last one (the target attribute 'cnt')\n",
    "# this can be enumerated with an index using https://docs.python.org/3/library/functions.html#enumerate\n",
    "# position in the axes: vector [i,j] with i is the line number, and j the column index\n",
    "for idx, feature in enumerate(df_train.columns[:-1]):\n",
    "    df.plot(feature, \"cnt\", subplots=True,  kind=\"scatter\", ax=axes[idx // 4, idx % 4]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not so easy to have some quantitative impression from scatter plots of categorical variables. Boxplots can be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2,3,1)\n",
    "sns.boxplot(x = 'season', y = 'cnt', data = df_train)\n",
    "plt.subplot(2,3,2)\n",
    "sns.boxplot(x = 'mnth', y = 'cnt', data = df_train)\n",
    "plt.subplot(2,3,3)\n",
    "sns.boxplot(x = 'weathersit', y = 'cnt', data = df_train)\n",
    "plt.subplot(2,3,4)\n",
    "sns.boxplot(x = 'holiday', y = 'cnt', data = df_train)\n",
    "plt.subplot(2,3,5)\n",
    "sns.boxplot(x = 'weekday', y = 'cnt', data = df_train)\n",
    "plt.subplot(2,3,6)\n",
    "sns.boxplot(x = 'workingday', y = 'cnt', data = df_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Based on these plots, describe features which have an influence on the target attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots suggest that there is a linear dependence between the target and some features such *temp* or *atemp*. There are also noticeable correlations with *mnth* and *season*. There seems to be also more rentals on working days, and when the weather is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization\n",
    "\n",
    "The sizes of the data entries are on rather different scales, as made precise through the output of the *describe()* function above. We therefore renormalize the data by rescaling the features, so that all entries are between 0 and 1 (see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_train[:] = scaler.fit_transform(df_train[:])\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum and maximum are indeed 0 and 1 for all variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and target correlations\n",
    "\n",
    "We now estimate more quantitatively the level of linear dependence between the features and the target variable. A good measure of the linear relationship between two vectors is the [Pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) (see also Chapter 25 [Shalev-Shwartz] for a discussion on how it relates to feature selection). \n",
    "\n",
    "Correlations can also be computed with the *pandas* library, using the dataframe method *corr* (see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html), and plotted with the heatmap function of the statistical data visualization library *seaborn* (see https://seaborn.pydata.org/generated/seaborn.heatmap.html)/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "# sns.set_theme()\n",
    "# other 'Diverging colormaps' can be used, see https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "sns.heatmap(df_train.corr(method='pearson'), annot = True, linewidths=.5, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next break down the correlations into correlations between the variables we are looking for to predict the result, and correlations between these variables and the target attribute *cnt*. The latter correlations can be computed with the function *corrwith* (see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corrwith.html), which needs as argument another dataframe as an argument to compute the pairwise correlations with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_train_variables is df_train without the column of the target attribute 'cnt'\n",
    "# alternative command: use df[df.columns.difference(['cnt'])]\n",
    "df_train_variables = df_train[df_train.columns[:-1]]\n",
    "# get features correlation coefficients\n",
    "df_train_variables.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quantities are strongly correlated (in particular *temp* and *atemp*). This will require some care when choosing the features for prediction.\n",
    "\n",
    "We next compute correlations with the target attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_variables.corrwith(df_train['cnt'], axis=0, method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Compare these numbers with the corresponding ones in the heatmap above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recover the numbers displayed in the heatmap above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample above shows features correlations with the target. Some of them (in fact, all of of them) are not *null*. This means that it makes sense to try to predict the output using a linear method (although in the end it may not be sufficient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with all features (despite strong correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some attributes in our dataset have strong correlations (one speaks of *multicollinearity*, see https://en.wikipedia.org/wiki/Multicollinearity), which can lead to issues in solving the regression problem, as the design matrix may be ill-conditioned. We start by a naive estimation where we pretend that we have not noticed the strong correlations, in order to highlight the kind of problems that arise.\n",
    "\n",
    "We start by decomposing the train data into the features $X$ and the target attribute $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "# df_shuffled = shuffle(df, random_state=123)\n",
    "df_train, df_test = train_test_split(df, train_size = fraction_train, test_size = fraction_test)\n",
    "df_train[:] = scaler.fit_transform(df_train[:])\n",
    "X = df_train[df_train.columns[:-1]]\n",
    "y = df_train[\"cnt\"]\n",
    "df_test[:] = scaler.transform(df_test[:]) \n",
    "X_test = df_test[df_test.columns[:-1]]\n",
    "y_test = df_test[\"cnt\"]\n",
    "print(X.head())\n",
    "print('\\n------------------------------------\\n')\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Check that the test data has been properly normalized. Are the minima and maxima of all features 0 and 1, respectively? If not, why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the rescaling of the train data. It is therefore possible that some features in the test do not span all the values between 0 and 1 (for instance, the minimum can be below 0; or the maximum below 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain training of a linear model\n",
    "\n",
    "We first do some training on the whole data set, with all features kept.\n",
    "\n",
    "**Question 4.** Train a linear regression model on the training dataset and look at the feature weights. The acquired weights are in the *coef_* parameter of a regressor class. It is good to re-run the estimation several times by randomly re-splitting the data set into train and test sets. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# build a model\n",
    "linear_regressor = linear_model.LinearRegression() \n",
    "# train the model using all data\n",
    "linear_regressor.fit(X, y) \n",
    "# output coefficients\n",
    "print('\\nCoefficients and their weights:')\n",
    "# zip function to aggregate https://docs.python.org/3.3/library/functions.html#zip\n",
    "# \"{:.3f}\".format(number) to display number with 3 decimal places\n",
    "# or alternatively round(number,3), as used below\n",
    "for pair in zip(df_train.columns, linear_regressor.coef_):\n",
    "  print(pair[0],' -> ',\"{:.3f}\".format(pair[1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the weights for linearly dependent features are significantly greater in absolute values than for other features. More importantly, when re-running the fitting procedure with newly randomly split train/test sets, the weights for these features change dramatically (look for instance at *temp* and *atemp*; although, interestingly, the sums of these weights is more or less constant) -- as opposed to other weights, such as *yr*, which are quite stable. This is related to the fact that the matrix $X^T X$ is ill-conditioned when two features are too strongly correlated, so that the linear system $X^T X w = X^T y$ defining $w$ is difficult to solve, in the sense that small variations in $y$ can lead to strong variations in $w$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remainder of this notebook, we remove the *temp* field, and only keep *atemp*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('temp',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with some regularization \n",
    "We next consider training with some regularization in order to obtain the best bias/variance trade-off. The norm of weights multiplied by the regularization coefficient $\\alpha$ is added to the cost function to minimize. We consider both lasso ($\\ell^1$ norm) and ridge ($\\ell^2$ norm) regression. We train the associated regularized cost functions with their defaults parameters, see https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html and https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One shot training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the optimization with lasso and ridge regression various times, by randomly reshuffling the data set in order to get some intuition on the variability of the coefficients. We work here only on the training data, and do not test yet the quality of the prediction on the test set.\n",
    "\n",
    "**Question 5.** Change the value of the regularization parameter $\\alpha$ in order to see the impact on the fitted coefficients. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.01)\n",
    "df_train, df_test = train_test_split(df, train_size = fraction_train, test_size = fraction_test)\n",
    "df_train[:] = scaler.fit_transform(df_train[:])\n",
    "X = df_train[df_train.columns[:-1]]\n",
    "y = df_train[\"cnt\"]\n",
    "lasso.fit(X, y)\n",
    "print('Intercept -> ', round(lasso.intercept_,3))\n",
    "for pair in zip(df_train.columns, lasso.coef_):\n",
    "  print(pair[0],' -> ',\"{:.3f}\".format(pair[1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large values of $\\alpha$, many coefficients are 0, and the non zero coefficients are rather stable from one realization of the test/train split to the other. For small values of $\\alpha$, almost all coefficients are non zero, and can substantially change from one realization to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Do the same for ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.0001)\n",
    "ridge.fit(X, y)\n",
    "print('Intercept -> ', round(ridge.intercept_,3))\n",
    "for pair in zip(df_train.columns, ridge.coef_):\n",
    "  print(pair[0],' -> ',\"{:.3f}\".format(pair[1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients for ridge regression and lasso are quite similar for small values of the regularization parameter. A nice aspect of lasso regression though is that it puts to 0 uninformative features, whereas ridge regression still assigns them a non zero (although small) coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training paths\n",
    "\n",
    "We now explore more systematically the dependence of the result as a function of the regularization coefficient. The aim is to find the best value of $\\alpha$ for prediction, using the test set. Before doing this, we look more closely at how the coefficients of the fit change as $\\alpha$ is increased.\n",
    "\n",
    "For each coefficient value from the vector of values *alphas_lasso* for the parameter $\\alpha$, we train the Lasso regressor and write the weights into the corresponding rows of the *coefs_lasso* matrix. The same is then done for ridge regression. This will allow us to look at how coefficients vary as $\\alpha$ is changed. Note that it would be possible instead to plot results as a function of the magnitude of the coefficients, using the scikit-learn function https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lars_path.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use coefficients logarithmically spaced in order to cover a wide range of values \n",
    "alphas_lasso = np.logspace(-5, 1, 100)\n",
    "coefs_lasso = np.zeros((alphas_lasso.shape[0], X.shape[1])) \n",
    "\n",
    "for i, al in enumerate(alphas_lasso):\n",
    "    lasso = Lasso(alpha = al)\n",
    "    lasso.fit(X, y)\n",
    "    for j, coef in enumerate(lasso.coef_):\n",
    "        coefs_lasso[i][j] = coef\n",
    "        \n",
    "plt.figure(figsize=(10, 8))\n",
    "for coef, feature in zip(coefs_lasso.T, df.columns):\n",
    "    plt.semilogx(alphas_lasso, coef, label=feature)\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.4, 0.95))\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Feature weight\")\n",
    "plt.title(\"Lasso regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next do the same for ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_ridge = np.logspace(-5, 4, 100)\n",
    "coefs_ridge = np.zeros((alphas_ridge.shape[0], X.shape[1]))\n",
    "\n",
    "for i, al in enumerate(alphas_ridge):\n",
    "    ridge = Ridge(alpha = al)\n",
    "    ridge.fit(X, y)\n",
    "    for j, coef in enumerate(ridge.coef_):\n",
    "        coefs_ridge[i][j] = coef\n",
    "        \n",
    "plt.figure(figsize=(10, 8))\n",
    "for coef, feature in zip(coefs_ridge.T, df.columns):\n",
    "    plt.semilogx(alphas_ridge, coef, label=feature)\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.4, 0.95))\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Feature weight\")\n",
    "plt.title(\"Ridge regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration, we can also compute the regression path as a function of the magnitude of the coefficients, for lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes need to be converted to numpy format\n",
    "XX = X.to_numpy()\n",
    "yy = y.to_numpy()\n",
    "_, _, coefs = linear_model.lars_path(XX, yy, method=\"lasso\")\n",
    "\n",
    "# plot the corresponding result\n",
    "tau = np.sum(np.abs(coefs.T), axis=1)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.xlabel(\"L1 norm of coefficients\")\n",
    "plt.plot(tau, coefs.T, marker=\"o\")\n",
    "plt.legend(list(df.columns), bbox_to_anchor=(1.4, 0.95))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** What are the largest coefficients? Which coefficients are the most important? (in the sense that they are non zero first when performing lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, in all these plots, the coefficient for the year is large and positive, and is the first one to be non zero when decreasing the penalty coefficient (starting from a large value). This is because there were more rentals in average in the second year (as we check below; see the last column 'cnt' in the reported statistics). The average of the other features are rather similar. This could be due to the fact that the bike rental system was better known the second year, and therefore attracted more customers, irrespectively of weather conditions, etc. \n",
    "\n",
    "The coefficient related to the working day is the first one to be non zero when looking at the LARS path, but it eventually converges to a rather small value.\n",
    "\n",
    "Moreover, the coefficient corresponding to temperature is large, and, to a lesser extent, the one related to the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df[\"yr\"] == 0]\n",
    "df_1 = df[df[\"yr\"] == 1]\n",
    "print('Statistics for the first year \\n')\n",
    "print(df_0.describe())\n",
    "print('\\n ------------------------------ \\n')\n",
    "print('Statistics for the second year \\n')\n",
    "print(df_1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "We next perform cross validation in order to choose the best coefficient. The metric for the quality of the results is the mean square error (MSE) computed on the test set. We explore two approaches: randomly splitting the full data set into test/train sets, or using k-fold cross validation. For the latter method, we use built-in routines in scikit-lean to divide the sample into $k$ blocks, each of them being considered as a test set when training is performed on the remaining $k-1$ blocks. The MSE for a given value of $\\alpha$ is averaged over the test MSEs over the folds. \n",
    "\n",
    "We start by computing the MSE and the regression score for a given value of $\\alpha$ in a pedestrian way, in order to get a feeling for what is being done. Everything is done for Lasso, but the adaptation to ridge regression would be straightforward.\n",
    "\n",
    "**Question 8.** Complete the code below: in one case, you need to compute 'by hand' something computed by a built-in scikit-learn function, and in the other case you need on the contrary to use a built-in scikit-learn function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = 0.0001\n",
    "\n",
    "df_train, df_test = train_test_split(df, train_size = fraction_train, test_size = fraction_test)\n",
    "df_train[:] = scaler.fit_transform(df_train[:])\n",
    "X = df_train[df_train.columns[:-1]]\n",
    "y = df_train[\"cnt\"]\n",
    "df_test[:] = scaler.transform(df_test[:])\n",
    "X_test = df_test[df_test.columns[:-1]]\n",
    "y_test = df_test[\"cnt\"]\n",
    "\n",
    "lasso = Lasso(alpha = al)\n",
    "lasso.fit(X, y)\n",
    "# report coefficients\n",
    "print('Intercept:', lasso.intercept_)\n",
    "print( 'Rounded coef:', list(map(lambda c: round(c, 3) , lasso.coef_) )) \n",
    "# see function score() on https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "print('\\nR2  (train) = ',lasso.score(X,y))\n",
    "y_pred = lasso.predict(X)\n",
    "E2_test = ((y-y_pred)**2).sum() \n",
    "print('R2  (train) = ',1-E2_test/sum( (y-np.mean(y))**2 ),' computed by hand')\n",
    "# we next compute the MSE equivalently \n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('MSE (train) = ',mean_squared_error(lasso.predict(X), y))\n",
    "print('MSE (train) = ',((y-lasso.predict(X))**2).mean(),' computed by hand\\n')\n",
    "# compute the prediction error on the test set\n",
    "# one can check that this is equivalent to lasso.intercept_+sum(lasso.coef_*X[i]) for each index i  \n",
    "y_pred = lasso.predict(X_test)\n",
    "print('R2   (test) = ',lasso.score(X_test,y_test))\n",
    "print('MSE  (test) = ',((y_test-y_pred)**2).mean())\n",
    "# plotting the results\n",
    "plt.title('Correlation between actual and predicted values')\n",
    "plt.xlabel('actual values')\n",
    "plt.ylabel('predicted values')\n",
    "plt.scatter(y_test,y_pred,color='royalblue')\n",
    "plt.plot([0,1],[0,1],color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now more precisely quantify the variability of the outputs by performing several realizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = 0.0001\n",
    "nb_real = 100\n",
    "\n",
    "R2_test = np.zeros(nb_real) \n",
    "MSE_test = np.zeros(nb_real)\n",
    "\n",
    "lasso = Lasso(alpha = al)\n",
    "for real in range(nb_real):\n",
    "  df_train, df_test = train_test_split(df, train_size = fraction_train, test_size = fraction_test)\n",
    "  df_train[:] = scaler.fit_transform(df_train[:])\n",
    "  X_train = df_train[df_train.columns[:-1]]\n",
    "  y_train = df_train[\"cnt\"]\n",
    "  lasso.fit(X, y)\n",
    "  df_test[:] = scaler.transform(df_test[:])\n",
    "  X_test = df_test[df_test.columns[:-1]]\n",
    "  y_test = df_test[\"cnt\"]\n",
    "  R2_test[real] = lasso.score(X_test,y_test)\n",
    "  # equivalently one could use a built-in function: \n",
    "  # import function as --> from sklearn.metrics import mean_squared_error \n",
    "  # call function as --> mean_squared_error(y_pred, y)\n",
    "  # with y_pred = lasso.predict(X)\n",
    "  MSE_test[real] = ((y_test-lasso.predict(X_test))**2).mean() \n",
    "    \n",
    "print('Average R2  (test) =', R2_test.mean())\n",
    "print('Average MSE (test) =', MSE_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, one rather uses a single data set, and relies on built-in cross validation function such as [__LassoCV__](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html). It takes as input a list of values of $\\alpha$ and calculates the MSE for each of them. After training, the regressor will contain the variable __mse\\_path\\___, a matrix of size `len(alpha) x n_folds`, where `n_folds` (the number of blocks in cross-validation), containing the MSE values on the test for the corresponding runs. In addition, the variable __alpha\\___ will store the selected (optimal) value of the regularization parameter, and in __coef\\___, will have the trained weights corresponding to this __alpha___.\n",
    "\n",
    "Note that the regressor can change the order in which it iterates through the alphas values. In order to map it to the MSE matrix, it is better to use the regressor variable __alphas___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, train_size = fraction_train, test_size = fraction_test)\n",
    "df_train[:] = scaler.fit_transform(df_train[:])\n",
    "X_train = df_train[df_train.columns[:-1]]\n",
    "y_train = df_train[\"cnt\"]\n",
    "\n",
    "alphas_lasso = np.logspace(-7, -3, 500)\n",
    "nb_folds = 10\n",
    "reg = LassoCV(cv=nb_folds, alphas = alphas_lasso)\n",
    "reg.fit(X, y)\n",
    "print('Regularizator score (R2 coefficient):', reg.score(X, y))\n",
    "print('Regularizator\\'s optimal alpha value:', reg.alpha_)\n",
    "print('Regularizator coefficients:')  \n",
    "[(pair[0], round(pair[1], 4)) for pair in zip(df.columns[:-1], reg.coef_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the MSE as a function of $\\alpha$ to check how much is gained in the cross validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mse_arr = np.array(reg.mse_path_).mean(axis=1)\n",
    "plt.figure(figsize=(10, 8)) \n",
    "plt.semilogx(reg.alphas_, mean_mse_arr, label=feature )\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Mean MSE by fold\")\n",
    "plt.title(\"Lasso regularizator MSE\")\n",
    "#plt.ylim(0.011869,0.011872)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross validation for ridge regression \n",
    "# see https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, train_size = fraction_train, test_size = fraction_test)\n",
    "df_train[:] = scaler.fit_transform(df_train[:])\n",
    "X_train = df_train[df_train.columns[:-1]]\n",
    "y_train = df_train[\"cnt\"]\n",
    "\n",
    "alphas_ridge = np.logspace(-5, 1, 500)\n",
    "# doing \"leave one out cross validation\" by default \n",
    "reg = RidgeCV(cv=None, alphas = alphas_ridge, scoring=None, store_cv_values=True)\n",
    "reg.fit(X, y)\n",
    "print('Regularizator score (R2 coefficient):', reg.score(X, y))\n",
    "print('Regularizator\\'s optimal alpha value:', reg.alpha_)\n",
    "print('Regularizator coefficients:')  \n",
    "[(pair[0], round(pair[1], 4)) for pair in zip(df.columns[:-1], reg.coef_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mse_arr = np.array(reg.cv_values_).mean(axis=0)\n",
    "plt.figure(figsize=(10, 8)) \n",
    "plt.semilogx(alphas_ridge, mean_mse_arr, label=feature )\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Mean MSE by fold\")\n",
    "plt.title(\"Ridge regularizator MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9.** What do you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not gaining much with lasso and ridge regression. The coefficients found by the two regularization strategies are rather similar. However, the accuracy is not great. It seems that the model is not able to make good predictions. More complex models should be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
