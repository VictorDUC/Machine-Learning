{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest neighbors\n",
    "\n",
    "We consider a simple supervised classification method based on similarity between inputs, in order to highlight issues related to model validation (choice of hyperparameters). Essentially, it consists in finding the $K$ nearest neighboring point of a new data point, and predict the label of the new data point based on the empirical frequencies within the $K$ neighbors which were found. When $K=1$, the training error is 0, but the test error may be large as overfitting is observed. When $K$ is large, the decision boundaries are much smoother, but the large number of neighbors considered leads to underfitting and large training errors (hence also large test errors).\n",
    "\n",
    "**There are 8 questions to answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example with decision boundaries\n",
    "\n",
    "We first visualize the behavior of kNN with decision boundaries. The code below is based on \n",
    "https://colab.research.google.com/github/tvhahn/Beautiful-Plots/blob/master/Decision%20Boundary/decision-boundary.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import neighbors\n",
    "import seaborn as sns;\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the iris dataset https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html There are three possible labels: 0,1,2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to pandas dataframe \n",
    "df = pd.DataFrame(data=x, columns=iris.feature_names)\n",
    "df['label'] = pd.Series(iris.target_names[y], dtype='category')\n",
    "\n",
    "# plot the results\n",
    "palette = {'setosa': 'orange', 'versicolor': 'green', 'virginica': 'purple'}\n",
    "sns.pairplot(df, vars = df.columns[0:4], hue=\"label\", palette=palette)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retain only the first two columns of the $x$ points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data[:,0:2] \n",
    "y = iris.target\n",
    "\n",
    "# print the shape of the data to\n",
    "# better understand it\n",
    "print('data shape:', x.shape)\n",
    "print('label shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the x0, x1 feature\n",
    "x0 = x[:,0]\n",
    "x1 = x[:,1]\n",
    "\n",
    "chosen_colors = np.array(['blue', 'red', 'black'])\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(x0, x1, c=chosen_colors[y])\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the K-nearest neighbor method implemented in Scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = 10 # KNN number of neighbors\n",
    "clf = neighbors.KNeighborsClassifier(N_NEIGHBORS, weights='uniform')\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a grid to evaluate the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 1.0 # how much to \"pad\" around the min/max values of the data, to set the bounds of the plots\n",
    "H = 0.1 # mesh stepsize\n",
    "\n",
    "# creating the mesh\n",
    "x0_min, x0_max = np.round(x0.min())-PAD, np.round(x0.max()+PAD)\n",
    "x1_min, x1_max = np.round(x1.min())-PAD, np.round(x1.max()+PAD)\n",
    "x0_axis_range = np.arange(x0_min,x0_max,H)\n",
    "x1_axis_range = np.arange(x1_min,x1_max,H)\n",
    "xx0, xx1 = np.meshgrid(x0_axis_range, x1_axis_range)\n",
    "\n",
    "# checking the shape of the mesh\n",
    "print('Mesh size')\n",
    "print('xx0.shape:', xx0.shape)\n",
    "print('xx1.shape:', xx1.shape,'\\n')\n",
    "\n",
    "# reshaping all grid points as lines, using ravel() to flatten\n",
    "# see https://numpy.org/doc/stable/reference/generated/numpy.ravel.html\n",
    "xx = np.stack((xx0.ravel(),xx1.ravel()),axis=1)\n",
    "print('After reshaping')\n",
    "print('xx.shape:', xx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next compute predictions on the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction at all grid points: \n",
    "# - probability vector (3 dimensional vector with entries summing to 1)\n",
    "yy_prob = clf.predict_proba(xx) \n",
    "# - class of maximal probability\n",
    "yy_hat = clf.predict(xx) \n",
    "                               \n",
    "# for display: size of each probability dot\n",
    "yy_size = np.max(yy_prob, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the decision boundaries and various other useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters for dots in scatter plots\n",
    "PROB_DOT_SCALE = 40       # modifier to scale the probability dots\n",
    "PROB_DOT_SCALE_POWER = 3  # exponential used to increase/decrease size of prob dots\n",
    "TRUE_DOT_SIZE = 40        # size of the true labels\n",
    "\n",
    "# Choice of colors and colormap (using colors adequate for color blind people, see https://bit.ly/3qJ6LYL)\n",
    "redish = '#d73027'\n",
    "orangeish = '#fc8d59'\n",
    "yellowish = '#fee090'\n",
    "blueish = '#4575b4'\n",
    "colormap = np.array([redish,blueish,orangeish])\n",
    "\n",
    "from matplotlib.lines import Line2D       # for creating the custom legend\n",
    "from matplotlib import pyplot             # to re-add a legend later on\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid(False) # remove gridlines \n",
    "\n",
    "# We start by plotting the training data \n",
    "# The parameter zorder is set to a positive value so that the dots appear above all other elements \n",
    "plt.scatter(x[:,0], x[:,1], c=colormap[y], s=TRUE_DOT_SIZE, zorder=1, linewidths=0.7, edgecolor='k')\n",
    "\n",
    "# We first plot the dots corresponding to the estimation at the grid points \n",
    "# The positions are defined by the xx values, and the color by the KNN predictions yy_hat\n",
    "# The size of the dots is proportional to yy_size^3 \n",
    "plt.scatter(xx[:,0],xx[:,1],c=colormap[yy_hat],alpha=0.4,s=PROB_DOT_SCALE*yy_size**PROB_DOT_SCALE_POWER)\n",
    "\n",
    "# We next represent contours plot\n",
    "# The yy_hat has to be reshaped as a matrix corresponding to the x0 and x1 axes\n",
    "# The number of levels was manually tuned for this data, and would need to be changed for more classes\n",
    "plt.contour(x0_axis_range, x1_axis_range,np.reshape(yy_hat,(xx0.shape[0],-1)),\n",
    "            levels=3,linewidths=1,colors=[redish,blueish, blueish,orangeish,])\n",
    "\n",
    "# axes names\n",
    "plt.ylabel('Sepal length')\n",
    "plt.xlabel('Sepal width')\n",
    "\n",
    "# first legend: classes\n",
    "legend_class = []\n",
    "for flower_class, color in zip(['c', 's', 'v'], [blueish, redish, orangeish]):\n",
    "    legend_class.append(Line2D([0], [0], marker='o', label=flower_class,ls='None',markerfacecolor=color, \n",
    "        markersize=np.sqrt(TRUE_DOT_SIZE),markeredgecolor='k', markeredgewidth=0.7))\n",
    "legend1 = plt.legend(handles=legend_class, loc='center',bbox_to_anchor=(1.05, 0.35),frameon=True,title='class')\n",
    "# second legend: probabilities\n",
    "prob_values = [0.4, 0.6, 0.8, 1.0]\n",
    "legend_prob = []\n",
    "for prob in prob_values:\n",
    "    legend_prob.append(Line2D([0], [0], marker='o', label=prob, ls='None', alpha=0.8,markerfacecolor='grey', \n",
    "        markersize=np.sqrt(PROB_DOT_SCALE*prob**PROB_DOT_SCALE_POWER),markeredgecolor='k', markeredgewidth=0))\n",
    "legend2 = plt.legend(handles=legend_prob, loc='center',bbox_to_anchor=(1.05, 0.65),frameon=True,title='probability')\n",
    "# to re-add the first legend, erased after the second one is plotted\n",
    "pyplot.gca().add_artist(legend1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Change the values of $K$ and discuss how the decision boundaries change. Consider also using the petal width and length instead of the sepal width and length. Describe in the cell below your observations, and say also which lines of code need to be changed to use the petal data instead of the sepal one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decisions boundaries are smoother when $K$ increases.\n",
    "\n",
    "The line of code for changing to petal data is below. Classification is better with petal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data[:,2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the number of neighbors by cross-validation\n",
    "\n",
    "Since data is scarce and cannot be generated, we consider cross-validation to estimate the optimal number of neighbords $K$ to consider. We first use the built-in scikit-learn function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# creating list of K for KNN\n",
    "k_list = list(range(1,50,2))\n",
    "# creating list of cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform n-fold cross validation\n",
    "for k in k_list:\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, x, y, cv=n_fold, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "# changing to misclassification error\n",
    "MSE = [1 - t for t in cv_scores]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Optimal number of neighbors', fontsize=20)\n",
    "plt.xlabel('Number of Neighbors K', fontsize=15)\n",
    "plt.ylabel('Misclassification Error', fontsize=15)\n",
    "plt.plot(k_list, MSE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Write a short code giving the optimal number of neighbors found by cross validation. How does this number change when the number of folds is varied?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is quite some variability when changing the number of folds... The estimates are not very reliable since the number of data points is rather small. There is however some plateau in the missclassification errors, so that several values of $K$ are suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = k_list[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d.\" % best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing KNN from scratch\n",
    "\n",
    "We now implement KNN from scratch -- first the method itself, and then cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Complete, in the code below, the function *_predict*, which predicts the label for a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class KNN:\n",
    "\n",
    "    # initialization\n",
    "    def __init__(self, K=3):\n",
    "        self.k = k\n",
    "\n",
    "    # memorizing the training set in order to make predictions\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    # calling the function _predict on each input point in order to perform prediction for a vector of inputs\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    # actual prediction function ---------> TO COMPLETE \n",
    "    def _predict(self, x):\n",
    "        label = 0\n",
    "        # Compute distances between x and all examples in the training set\n",
    "        distances = [np.sum((x-x_train)**2) for x_train in self.X_train]\n",
    "        # Sort by distance and return indices of the first k neighbors\n",
    "        # cf. https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
    "        k_idx = np.argsort(distances)[:self.k]\n",
    "        # Extract the labels of the k nearest neighbor training samples\n",
    "        k_neighbor_labels = [self.y_train[i] for i in k_idx]  \n",
    "        # return the most common class label\n",
    "        # see https://docs.python.org/3/library/collections.html#collections.Counter.most_common\n",
    "        most_common = Counter(k_neighbor_labels).most_common(1)\n",
    "        label = most_common[0][0]\n",
    "        return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first do a validation based on splitting the data intro a training and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "\n",
    "# we first shuffle the data\n",
    "Ndata = x.shape[0]\n",
    "indices = np.random.permutation(Ndata) \n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# we then separate it into a train and validation set\n",
    "N_train = round(split_ratio*Ndata)\n",
    "x_train = x[0:N_train]\n",
    "y_train = y[0:N_train]\n",
    "x_validation = x[N_train:Ndata]\n",
    "y_validation = y[N_train:Ndata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# creating list of K for KNN\n",
    "k_list = list(range(1,50,2))\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for k in k_list:\n",
    "  model = KNN(K = k)\n",
    "  model.fit(x_train, y_train)\n",
    "  pred = model.predict(x_validation)\n",
    "  # compute the fraction of correctly predicted labels using built-in functions\n",
    "  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "  acc = accuracy_score(y_validation, pred)\n",
    "  accuracies.append(acc)\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(k_list,accuracies)\n",
    "plt.xlabel('Value of K')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If one wants to see how the maximal number of occurences is found, an option is to change the _predict function\n",
    "# by asking it to return label, most_common, and the running the lines below\n",
    "model = KNN(K = 10)\n",
    "model.fit(x_train, y_train)\n",
    "model._predict(x_validation[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data set is small, it is in fact better to code cross-validation.\n",
    "\n",
    "**Question 4.** Complete the code below to implement cross-validation:\n",
    "- The function *kfold_split* splits the training inputs into the desired number of folds, by returning a list of indices, the i-th element of the list being of the set of indices of input points in the i-th fold.\n",
    "- The function *custom_cross_val_score* returns the mean prediction score based on an average over the results obtained by taking one fold as the validation set, and the remaining folds as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the list of indices to consider for each fold\n",
    "def kfold_split(Ndata, n_folds):\n",
    "    indices_list = []\n",
    "    n_elements = int(Ndata/n_folds) # number of elements to consider in each fold\n",
    "    indices = np.random.permutation(Ndata) # shuffle the set of integers 1, 2, ..., Ndata \n",
    "    for i in range(n_folds):\n",
    "        # append to indices_list the array of indices corresponding to the i-th fold\n",
    "        indices_list.append(indices[i*n_elements:(i+1)*n_elements])    \n",
    "    return indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments of the function = full data set (x,y), value of k for KNN, and number of folds to consider\n",
    "def custom_cross_val_score(x, y, k, n_fold):\n",
    "    model = KNN(K = k)\n",
    "    score = np.zeros(n_fold)\n",
    "    # indices for each fold\n",
    "    ind = kfold_split(x.shape[0],n_fold)\n",
    "    # loop over the folds\n",
    "    for i in range(n_fold):\n",
    "        # creation of the train set = full dataset without i-th fold\n",
    "        # using the function https://numpy.org/doc/stable/reference/generated/numpy.delete.html\n",
    "        # could alternatively consider concatenating with np.concatenate, but longer to code...\n",
    "        xtrain = np.delete(x,ind[i],0) # extra argument 0 to delete the full line and avoid flattening the array\n",
    "        ytrain = np.delete(y,ind[i])\n",
    "        # creation of the validation set = i-th fold\n",
    "        xval = x[ind[i]]\n",
    "        yval = y[ind[i]]\n",
    "        # we can now compute the predictions for these datasets\n",
    "        model.fit(xtrain, ytrain)\n",
    "        pred = model.predict(xval)\n",
    "        # add the score to the vector of scores\n",
    "        score[i] = accuracy_score(yval,pred)\n",
    "    return np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Run the cross-validation procedure with the custom function, and compare the results with the ones obtained by the built-in scikit-learn function (see above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are quite similar to the ones obtained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "\n",
    "# reload the dataset\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# creating list of K for KNN\n",
    "k_list = list(range(1,50,2))\n",
    "\n",
    "# creating list of cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform n-fold cross validation\n",
    "for k in k_list:\n",
    "    mean_score = custom_cross_val_score(x, y, k, n_fold)\n",
    "    cv_scores.append(mean_score)\n",
    "    \n",
    "# changing to misclassification error\n",
    "MSE = [1 - t for t in cv_scores]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Optimal number of neighbors', fontsize=20)\n",
    "plt.xlabel('Number of Neighbors K', fontsize=15)\n",
    "plt.ylabel('Misclassification Error', fontsize=15)\n",
    "plt.plot(k_list, MSE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data set\n",
    "\n",
    "In order to more quantitatively study KNN, and in particular have more inputs, we use the MNIST dataset (see http://yann.lecun.com/exdb/mnist/). We download the data from tensorflowts. There are 60,000 entries in the training data set, and 10,000 in the test set. Each data point is an image, encoded by a 28x28 matrix whose entries are integers between 0 and 255. We can performing various manipulations on the data:\n",
    "- change values, for instance by binarizing or rescaling to $[0,1]$\n",
    "- reshape the matrices into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up the random number generator: given seed for reproducibility, None otherwise\n",
    "# (see https://numpy.org/doc/stable/reference/random/generator.html#numpy.random.default_rng)\n",
    "my_seed = 1\n",
    "rng = np.random.default_rng(seed=my_seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from Keras, values between 0 and 255 initially\n",
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = tf.keras.datasets.mnist.load_data()\n",
    "print('initial data type for images = ',x_train_full.dtype,', initial data shape = ',x_train_full.shape)\n",
    "print('initial data type for labels = ',y_train_full.dtype,', initial label shape = ',y_train_full.shape,'\\n')\n",
    "    \n",
    "# renormalize to have data between 0 and 1; could alternatively use built-in rescaling function\n",
    "# such as https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "x_train_full = x_train_full/255. \n",
    "x_test_full = x_test_full/255.\n",
    "print('Train set: data set size =',x_train_full.shape[0])\n",
    "print('Test set:  data set size =',x_test_full.shape[0])\n",
    "\n",
    "# reshape the data points, which are 28x28 tensors, into a single vector of size 28x28=784\n",
    "x_train_full = x_train_full.reshape((x_train_full.shape[0], 784))\n",
    "x_test_full = x_test_full.reshape((x_test_full.shape[0], 784))\n",
    "\n",
    "# shuffle data\n",
    "indices = np.random.permutation(x_train_full.shape[0])\n",
    "x_train_full = x_train_full[indices]\n",
    "y_train_full = y_train_full[indices]\n",
    "indices = np.random.permutation(x_test_full.shape[0])\n",
    "x_test_full = x_test_full[indices]\n",
    "y_test_full = y_test_full[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the first elements of the resulting data set in order to see what they looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    # color map = binary, other choices here https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "    plt.imshow(x_train_full[i].reshape(28,28), cmap=plt.cm.binary)     \n",
    "    plt.title(y_train_full[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract a smaller data set for training since the method does not scale well with the number of data points (the data has already been shuffled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train subsampling rate: the final number of training images is 60000 divided by this number\n",
    "train_subsampling_rate = 25\n",
    "# test subsampling rate: the final number of training images is 10000 divided by this number\n",
    "test_subsampling_rate = 10\n",
    "\n",
    "# syntax for subsampling: start:sto:step \n",
    "x_train = x_train_full[0::train_subsampling_rate]\n",
    "y_train = y_train_full[0::train_subsampling_rate]\n",
    "print('Initial dimension of the training data:',x_train_full.shape)\n",
    "print('After subsampling at rate',train_subsampling_rate,':',x_train.shape)\n",
    "x_test = x_test_full[0::test_subsampling_rate]\n",
    "y_test = y_test_full[0::test_subsampling_rate]\n",
    "print('Initial dimension of the test data:',x_test_full.shape)\n",
    "print('After subsampling at rate',test_subsampling_rate,':',x_test.shape)\n",
    "\n",
    "# we replot some data to make sure that the data reduction was done correctly\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    # color map = binary, other choices here https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "    plt.imshow(x_train[i].reshape(28,28), cmap=plt.cm.binary)     \n",
    "    plt.title(y_train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Run the KNN method to identify the best value of $K$ by cross-validation (see code to complete below). Start by a rather broad range of values, and then refine by increasing the sizes of the datasets (both test and train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "\n",
    "# creating list of K for KNN\n",
    "k_list = list(range(1,20,2))\n",
    "# creating list of cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform n-fold cross validation\n",
    "for k in k_list:\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, x_train, y_train, cv=n_fold, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "# changing to misclassification error\n",
    "MSE = [1 - t for t in cv_scores]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Optimal number of neighbors', fontsize=20)\n",
    "plt.xlabel('Number of Neighbors K', fontsize=15)\n",
    "plt.ylabel('Misclassification Error', fontsize=15)\n",
    "plt.plot(k_list, MSE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write below the code to find the best value of $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding best k\n",
    "best_k = k_list[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d.\" % best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can in fact make use of the test set, used as a validation set.\n",
    "\n",
    "**Question 7.** Re-run the model validation procedure to identify the optimal value of $K$ by training the model on the training data, and computing the validation loss with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kVals = np.arange(1,10,2)\n",
    "accuracies = []\n",
    "\n",
    "for k in kVals:\n",
    "  model = KNN(K = k)\n",
    "  model.fit(x_train, y_train)\n",
    "  pred = model.predict(x_test)\n",
    "  # compute the fraction of correctly predicted labels using built-in functions\n",
    "  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "  acc = accuracy_score(y_test, pred)\n",
    "  accuracies.append(acc)\n",
    "  print(\"K = \"+str(k)+\": accuracy: \"+str(acc))\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(kVals,accuracies)\n",
    "plt.xlabel('Value of K')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding best k\n",
    "best_k = kVals[accuracies.index(max(accuracies))]\n",
    "print(\"The optimal number of neighbors is %d.\" % best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** Classification errors can also be quantified by looking at the confusion matrix. Compute this matrix for the optimal value of $K$ found in the previous question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNN(K = 5) # TO COMPLETE\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "acc = accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,pred) # could be normalized by the extra argument normalize='true' for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
