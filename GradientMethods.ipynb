{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient methods for optimization in Machine learning\n",
    "\n",
    "We test various optimization algorithms based on gradient methods (simple gradient, stochastic gradient, Nesterov accelerated gradient, Adam). In the first part of this notebook, we consider a simple two dimensional loss function $L(X)$ and try to minimize it with respect to the 2-dimensional variable $X$. In the second part of the notebook, we turn to the minimization of some training loss in the context of nonlinear regression. In this setting, the variable to be optimized is $\\theta$ and $X$ denotes training or test data.\n",
    "\n",
    "In both cases, you should play with the timestep/learning rate (denoted by $\\eta$ in this notebook) in order to have some efficient optimization.\n",
    "\n",
    "**There are 5 questions to answer.** The optional part has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#----- for scientific computing parts ------\n",
    "import numpy as np\n",
    "import math \n",
    "#---- for plots ------\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Optimizing two dimensional potentials\n",
    "\n",
    "### Defining potential energy functions and forces\n",
    "\n",
    "We use the MÃ¼ller-Brown potential, considered in various works in physics, for instance https://pubs.acs.org/doi/full/10.1021/acs.jctc.2c00314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class MullerBrown:\n",
    "\n",
    "    A = [-200.,-100.,-170.,15.]\n",
    "    a = [-1.,-1.,-6.5,0.7]\n",
    "    b = [0.,0,11.,0.6]\n",
    "    c = [-10.,-10.,-6.5,0.7]\n",
    "    x1ref = [1.,0,-0.5,-1.]\n",
    "    x2ref = [0.,0.5,1.5,1.]\n",
    "    \n",
    "    #--- potential energy function ---    \n",
    "    def L(self,x):\n",
    "        \"\"\"\n",
    "        :param x: array with x[0] first coordinate, and x[1] second coordinate\n",
    "        :return: float, value of the potential at x \n",
    "        \"\"\"\n",
    "        assert(type(x) == np.ndarray)\n",
    "        assert(x.ndim == 2)\n",
    "        assert(x.shape[1] == 2)\n",
    "        val = 0.\n",
    "        for i in range(0,len(self.A)):\n",
    "            arg = self.a[i]*(x[:,0]-self.x1ref[i])**2 \n",
    "            arg += self.b[i]*(x[:,0]-self.x1ref[i])*(x[:,1]-self.x2ref[i]) \n",
    "            arg += self.c[i]*(x[:,1]-self.x2ref[i])**2\n",
    "            val += self.A[i]*np.exp(arg)\n",
    "        \n",
    "        return val \n",
    "    \n",
    "    #--- partial derivative with respect to x ---\n",
    "    def dL_1(self,x):\n",
    "        \"\"\"\n",
    "        :param x: array with x[0] first coordinate, and x[1] second coordinate\n",
    "        :return: val: float, derivative of the loss with respect to x\n",
    "        \"\"\" \n",
    "        val = 0.\n",
    "        for i in range(0,len(self.A)):\n",
    "            arg = self.a[i]*(x[:,0]-self.x1ref[i])**2 \n",
    "            arg += self.b[i]*(x[:,0]-self.x1ref[i])*(x[:,1]-self.x2ref[i]) \n",
    "            arg += self.c[i]*(x[:,1]-self.x2ref[i])**2\n",
    "            deriv = 2*self.a[i]*(x[:,0]-self.x1ref[i]) + self.b[i]*(x[:,1]-self.x2ref[i]) \n",
    "            val += deriv*self.A[i]*np.exp(arg)\n",
    "        \n",
    "        return val\n",
    "    \n",
    "    #--- partial derivative with respect to y ---\n",
    "    def dL_2(self,x):\n",
    "        \"\"\"\n",
    "        :param x: array with x[0] first coordinate, and x[1] second coordinate\n",
    "\n",
    "        :return: val: float, derivative of the loss with respect to y\n",
    "        \"\"\" \n",
    "        val = 0.\n",
    "        for i in range(0,len(self.A)):\n",
    "            arg = self.a[i]*(x[:,0]-self.x1ref[i])**2 \n",
    "            arg += self.b[i]*(x[:,0]-self.x1ref[i])*(x[:,1]-self.x2ref[i]) \n",
    "            arg += self.c[i]*(x[:,1]-self.x2ref[i])**2\n",
    "            deriv = self.b[i]*(x[:,0]-self.x1ref[i]) + 2*self.c[i]*(x[:,1]-self.x2ref[i])\n",
    "            val += deriv*self.A[i]*np.exp(arg)\n",
    "        \n",
    "        return val\n",
    "    \n",
    "    #--- gradient of the loss ---\n",
    "    def nabla_L(self,x):\n",
    "        \"\"\"\n",
    "        :param x: array with x[0] first coordinate, and x[1] second coordinate\n",
    "        :return: np.array, array of gradients with respect to position vector, ndim = 2, shape = (,2)\n",
    "        \"\"\"\n",
    "        assert(type(x) == np.ndarray)\n",
    "        assert(x.ndim == 2)\n",
    "        assert(x.shape[1] == 2)\n",
    "        return np.column_stack( (self.dL_1(x), self.dL_2(x)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first check that partial derivatives have been correctly computed, by comparing the analytical formula to a second order approximation based on a centered finite difference. We do this for 3 points at the same time, to demonstrate that operations have been vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MullerBrown()\n",
    "X = np.random.rand(3,2) # 3 two dimensional points at random\n",
    "sigma = 10**(-4)\n",
    "deltaX1 = np.array([sigma,0])\n",
    "deltaX2 = np.array([0,sigma])\n",
    "print(\"Evaluation at X = \",X)\n",
    "print(\"\\nValues of the loss =\",loss.L(X))\n",
    "print(\"\\nPartial derivatives in direction 1 = \",loss.dL_1(X))\n",
    "print(\"Finite diff. approximations dir. 1 = \",(loss.L(X+deltaX1)-loss.L(X-deltaX1))/(2*sigma))\n",
    "print(\"\\nPartial derivatives in direction 2 = \",loss.dL_2(X))\n",
    "print(\"Finite diff. approximations dir. 2 = \",(loss.L(X+deltaX2)-loss.L(X-deltaX2))/(2*sigma))\n",
    "print(\"\\nGradients = \",loss.nabla_L(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the loss function to have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = MullerBrown()\n",
    "# x and y domains for the plots\n",
    "x_domain = [-1.6, 1.2] \n",
    "y_domain = [-0.35, 2] \n",
    "loss_min_max = [-150, 0] # bounds on values of the loss for plots \n",
    "\n",
    "gridx = np.linspace(x_domain[0], x_domain[1], 100)\n",
    "gridy = np.linspace(y_domain[0], y_domain[1], 100)\n",
    "x_plot = np.outer(gridx, np.ones(100)) \n",
    "y_plot = np.outer(gridy, np.ones(100)).T \n",
    "x2d = np.concatenate((x_plot.reshape(100 * 100, 1), y_plot.reshape(100 * 100, 1)), axis=1)\n",
    "loss_on_grid = loss.L(x2d).reshape(100,100)\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax0 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "ax0.set_title(\"Muller-Brown function\")\n",
    "#--- to fix angles // in colab, otherwise in notebook could rotate using the mouse/touchpad ---\n",
    "ax0.view_init(elev=20, azim=20) # play on the angles here to change the visualization\n",
    "ax0.plot_surface(x_plot, y_plot, loss_on_grid ,vmin=loss_min_max[0], vmax=loss_min_max[1], cmap='coolwarm', edgecolor='none')\n",
    "ax0.set_xlabel(\"x\")\n",
    "ax0.set_ylabel(\"y\")\n",
    "ax0.set_zlabel(\"V(x,y)\")\n",
    "ax0.set_zbound(loss_min_max[0], loss_min_max[1])\n",
    "ax1.pcolormesh(x_plot,y_plot,loss_on_grid,cmap='coolwarm',shading='auto',vmin=loss_min_max[0],vmax=loss_min_max[1])\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** What are the maximum and minimum values on the loss on this grid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( \"Minimum and maximum values of the loss: (%.4f, %.4f)\" % (loss_on_grid.min(), loss_on_grid.max()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple gradient method\n",
    "\n",
    "We start by running a simple gradient method as\n",
    "$$\n",
    "X^{n+1} = X^n - \\eta \\nabla L(X^n)\n",
    "$$\n",
    "This functions takes as argument a potential object, an initial condition, the number of simulation steps and a time step. It possibly records the value of the potential energy function at the points along the trajectory.initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def SimpleGradient(loss, X_0, eta=1e-3, Nepochs=1000, seed=None):\n",
    "    \"\"\"Performs a simple gradient dynamics \n",
    "\n",
    "    :param loss: must have methods for evaluation of the loss and its gradient \n",
    "    :param X_0: initial position, must be a 2D vector\n",
    "    :param eta: learning rate\n",
    "    :param Nepochs: number of iterations \n",
    "   \n",
    "    :return: traj and loss_values, which are both np.array\n",
    "    \"\"\"\n",
    "    dim = X_0.shape[0]\n",
    "    X = X_0.reshape(1,dim)\n",
    "    traj = []\n",
    "    loss_values = []\n",
    "    for i in range(Nepochs):\n",
    "        X = X - eta*loss.nabla_L(X.reshape(1,dim))\n",
    "        traj.append(X.reshape(dim,))\n",
    "        loss_values.append(loss.L(X))\n",
    "            \n",
    "    return np.array(traj), np.array(loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Play with the learning rate $\\eta$ to find a good value (large enough in order for the convergence not to be too slow, but not too large in order to prevent oscillations/non convergence). Check also what happens when starting from $X^0 =(0,0)$ instead of $X^0 = (-1,0.5)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timesteps are $10^{-4}$ lead to the fastest convergence. For smaller timesteps, the dynamics nicely converges but takes a long time to do so. For larger timesteps, oscillations are observed, the gradient dynamics does not converge.\n",
    "\n",
    "For the initial condition (0,0), the dynamics gets stuck in a local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.00002\n",
    "Nepochs = 1000\n",
    "seed = None \n",
    "x_0 = np.array([-1,0.5]) # initial condition; check also with [0.,0.]\n",
    "trajectory, loss_values = SimpleGradient(loss,x_0,eta,Nepochs,seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trajectory can then be plotted over the loss landscape, to check whether it converges to some local minimum. The values of the loss function should also be monitored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax0 = fig.add_subplot(1, 2, 1)\n",
    "colors = np.round(np.linspace(0,100,len(trajectory)))\n",
    "ax0.pcolormesh(x_plot,y_plot,loss_on_grid,cmap='coolwarm',shading='auto',vmin=loss_min_max[0],vmax=loss_min_max[1])\n",
    "ax0.scatter(trajectory[:,0], trajectory[:,1],s=5,c=colors,cmap='gray')\n",
    "ax0.set_title('Evolution of X')\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "ax1.plot(np.linspace(0,len(loss_values),len(loss_values)),loss_values)\n",
    "ax1.set_title('Evolution of the loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient dynamics\n",
    "\n",
    "We now consider the situation when the gradient is not exactly computed, but we have an unbiased stochastic estimator of it. In order to emulate SGD, we add a random component to the force, with average 0. This leads to the dynamics\n",
    "$$\n",
    "X^{n+1} = X^n + \\eta \\left( -\\nabla L(X^n) + \\sigma G^n\\right).\n",
    "$$\n",
    "The magnitude $\\sigma$ is fixed here, but it depends in practical situations on the minibatching size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(loss, X_0, eta, Nepochs, sigma, seed=None):\n",
    "    \"\"\"Performs stochastic gradient dynamics in an ideal setting \n",
    "\n",
    "    :param loss: must have methods for evaluation of the loss and its gradient \n",
    "    :param X_0: initial position, must be a 2D vector\n",
    "    :param eta: learning rate\n",
    "    :param Nepochs: number of iterations \n",
    "    :param sigma: magnitude of the minibatching noise\n",
    "   \n",
    "    :return: traj and loss_values, which are both np.array\n",
    "    \"\"\"\n",
    "    r = np.random.RandomState(seed)\n",
    "    dim = X_0.shape[0]\n",
    "    X = X_0.reshape(1,dim)\n",
    "    traj = []\n",
    "    loss_values = []\n",
    "    for i in range(Nepochs):\n",
    "        force = -loss.nabla_L(X.reshape(1,dim)) + sigma*r.normal(size=(dim,))\n",
    "        X = X + eta*force\n",
    "        traj.append(X.reshape(dim,))\n",
    "        loss_values.append(loss.L(X))\n",
    "            \n",
    "    return np.array(traj), np.array(loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Compare the behavior of SGD to simple gradient dynamics depending on the magnitude of $\\sigma$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note first that the dynamics gets sometimes stuck in a local minimum for certain realizations. For large noise, the minimization cannot be performed correctly unless the timestep is drastically reduced; essentially $\\sigma\\eta$ needs to be small. In this regime, SGD is similar to GD. When $\\sigma\\eta$ is of order 1, SGD remains in a vicinity of a local minimum, but rather samples values around this local minimum instead of performing some optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.00002\n",
    "sigma = 200\n",
    "Nepochs = 1000\n",
    "seed = None \n",
    "x_0 = np.array([-1,0.5]) # initial condition; check also with [0.,0.]\n",
    "trajectory, loss_values = SGD(loss,x_0,eta,Nepochs,sigma,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax0 = fig.add_subplot(1, 2, 1)\n",
    "colors = np.round(np.linspace(0,100,len(trajectory)))\n",
    "ax0.pcolormesh(x_plot,y_plot,loss_on_grid,cmap='coolwarm',shading='auto',vmin=loss_min_max[0],vmax=loss_min_max[1])\n",
    "ax0.scatter(trajectory[:,0], trajectory[:,1],s=5,c=colors,cmap='gray')\n",
    "ax0.set_title('Evolution of X')\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "ax1.plot(np.linspace(0,len(loss_values),len(loss_values)),loss_values)\n",
    "ax1.set_title('Evolution of the loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov accelerated gradient\n",
    "\n",
    "Using some inertia in the minimization procedure may be beneficial. Here, this means adding a momentum variable $V$ to the position variable $X$.\n",
    "\n",
    "**Question 4.** Implement the Nesterov accelerated gradient method seen in class, and find a relevant value of $\\beta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nesterov(loss, X_0, eta, beta, Nepochs, sigma, seed=None):\n",
    "    \"\"\"Performs Nesterov gradient descent in an ideal minibatching setting \n",
    "\n",
    "    :param loss: must have methods for evaluation of the loss and its gradient \n",
    "    :param X_0: initial position, must be a 2D vector\n",
    "    :param V_0: initial momentum\n",
    "    :param eta: learning rate\n",
    "    :param beta: refreshment parameter\n",
    "    :param Nepochs: number of iterations \n",
    "    :param sigma: magnitude of the minibatching noise\n",
    "   \n",
    "    :return: traj and loss_values, which are both np.array\n",
    "    \"\"\"\n",
    "    r = np.random.RandomState(seed)\n",
    "    dim = X_0.shape[0]\n",
    "    X = X_0.reshape(1,dim)\n",
    "    V = np.zeros((1,dim))\n",
    "    traj = []\n",
    "    loss_values = []\n",
    "    for i in range(Nepochs):\n",
    "        #--- Nesterov accelerated gradient ---\n",
    "        Y = X + beta*V\n",
    "        force = -loss.nabla_L(Y.reshape(1,dim)) + sigma*r.normal(size=(dim,))\n",
    "        V = beta*V + eta*force\n",
    "        X = X + V\n",
    "        traj.append(X.reshape(dim,))\n",
    "        loss_values.append(loss.L(X))\n",
    "            \n",
    "    return np.array(traj), np.array(loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run the dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.00002\n",
    "beta = 0.3\n",
    "sigma = 200\n",
    "Nepochs = 300\n",
    "seed = None \n",
    "x_0 = np.array([-1,0.5]) # initial condition; check also with [0.,0.]\n",
    "trajectory, loss_values = Nesterov(loss,x_0,eta,beta,Nepochs,sigma,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax0 = fig.add_subplot(1, 2, 1)\n",
    "colors = np.round(np.linspace(0,100,len(trajectory)))\n",
    "ax0.pcolormesh(x_plot,y_plot,loss_on_grid,cmap='coolwarm',shading='auto',vmin=loss_min_max[0],vmax=loss_min_max[1])\n",
    "ax0.scatter(trajectory[:,0], trajectory[:,1],s=5,c=colors,cmap='gray')\n",
    "ax0.set_title('Evolution of X')\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "ax1.plot(np.linspace(0,len(loss_values),len(loss_values)),loss_values)\n",
    "ax1.set_title('Evolution of the loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAM\n",
    "\n",
    "We next consider the Adam algorithm presented in https://arxiv.org/abs/1412.6980.\n",
    "\n",
    "**Question 5.** Implement the Adam method, and run it with the default suggested parameters $\\beta_1,\\beta_2$. How does the method compare to SGD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adam(loss, X_0, eta, beta1, beta2, Nepochs, sigma, eps, seed=None):\n",
    "    \"\"\"Performs Adam in an ideal setting \n",
    "\n",
    "    :param loss: must have methods for evaluation of the loss and its gradient \n",
    "    :param X_0: initial position, must be a 2D vector\n",
    "    :param eta: learning rate\n",
    "    :param Nepochs: number of iterations \n",
    "    :param sigma: magnitude of the minibatching noise\n",
    "   \n",
    "    :return: traj and loss_values, which are both np.array\n",
    "    \"\"\"\n",
    "    r = np.random.RandomState(seed)\n",
    "    dim = X_0.shape[0]\n",
    "    X = X_0.reshape(1,dim)\n",
    "    v = np.zeros((1,dim))\n",
    "    s = np.zeros((1,dim))\n",
    "    traj = []\n",
    "    loss_values = []\n",
    "    for i in range(Nepochs):\n",
    "        force = -loss.nabla_L(X.reshape(1,dim)) + sigma*r.normal(size=(dim,))\n",
    "        v = beta1*v + (1-beta1)*force\n",
    "        s = beta2*s + (1-beta2)*force**2\n",
    "        vh = v/(1-beta1**(i+1))\n",
    "        sh = s/(1-beta2**(i+1))\n",
    "        X = X + eta*vh*(np.sqrt(sh)+eps)**(-1)\n",
    "        traj.append(X.reshape(dim,))\n",
    "        loss_values.append(loss.L(X))\n",
    "            \n",
    "    return np.array(traj), np.array(loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run the dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "eps = 10**(-6)\n",
    "sigma = 2000\n",
    "Nepochs = 2000\n",
    "seed = None \n",
    "x_0 = np.array([-1,0.5]) # initial condition; check also with [0.,0.]\n",
    "trajectory, loss_values = Adam(loss,x_0,eta,beta1,beta2,Nepochs,sigma,eps,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax0 = fig.add_subplot(1, 2, 1)\n",
    "colors = np.round(np.linspace(0,100,len(trajectory)))\n",
    "ax0.pcolormesh(x_plot,y_plot,loss_on_grid,cmap='coolwarm',shading='auto',vmin=loss_min_max[0],vmax=loss_min_max[1])\n",
    "ax0.scatter(trajectory[:,0], trajectory[:,1],s=5,c=colors,cmap='gray')\n",
    "ax0.set_title('Evolution of X')\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "ax1.plot(np.linspace(0,len(loss_values),len(loss_values)),loss_values)\n",
    "ax1.set_title('Evolution of the loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
